{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n",
    "It is considered to be the best stock (not modified) classifier. This means you can take the classifier in its basic form and run it on the data, and the results will have low error rates. SVMs are supervised learning models fot both regression and classification. SVMs find applications in text mining, chemical classification, and image and handwriteing recognition. In the simples form, a SVM separates and predicts two classes of data by estimating the optimal vector plane or hyperplane between these two classes represented in vector space. \n",
    "\n",
    "A basic SVM is a non-probabilistic binary classifier that uses linear classification. SVMs can also be used to perform nonlinear classification over several classes. SVM often have a good generalization performance and also implement a kind of automatic complexity control to avoid overfitting. Hence SVMs are also called **large amrgin classifiers**.\n",
    "\n",
    "Another interesting fact about SVM is that they scale very well with the number of features being modeled and thus, SVMs are often used in machine learning problems that deal with a **large number of features**.\n",
    "\n",
    "**Pros**\n",
    "Low generalization error, computationally inexpensivem easy to repeat results\n",
    "\n",
    "**Cons**\n",
    "Sensitive to tuning parameters and kernel choice; natively only handles binary classifivation.\n",
    "\n",
    "**Works with**\n",
    "Numeric values, nominal values\n",
    "\n",
    "### Separating data with the maximum margin\n",
    "\n",
    "We need an **hyperplane** to separate the data. The hyperplane is the decision boundary. We'd like to find the point closest to the separating line as possible. This is known as **margin**. We want to have the greatest possible margin, because if we made a mistake trained our classifier on limited data, we'd like to be as robust as possible. SVM try to maximizae the maring by solving a quadratic optimization problem. The SMO algorithm allows tast training of SVMs by optimizing only two alphas at a time. \n",
    "\n",
    "The points closest to the separating hyperplane are known as **support vectors**. Now tha we know that we're trying to maximize the distance from the separating line to suppor vectors, we need to finde a way to optimize the problem.\n",
    "\n",
    "What happens if data is not linearly separable? We 're going to use something called a **kernel** to transform data into a form that's easily understood by the classifier. This can be called as *mapping from one feature space to another feature space*. Usually, his mapping goes from a lower dimensional feature space to a higher-dimensional space. This mapping is done by the kernel. After making the substitution, we can go about solving this linear problem in high-dimensional space, which is equivalent to solving a nonlinear problem in low-dimensional space. Replacing the inner product with a kernel is known as the *kernel trick of kernel substitution*. The *radial-bias* function is a popular kernel that measures the distance between two vectors.\n",
    "\n",
    "SVM are a **binary classifier** and additional methids can be extended to classification of classes greater than two. The performance of an SVM is also sensitive to classification parameters and parameters of the kernel used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"350\"\n",
       "            src=\"http://www.yaroslavvb.com/papers/rosasco-are.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1027952d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://www.yaroslavvb.com/papers/rosasco-are.pdf', width=700, height=350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
