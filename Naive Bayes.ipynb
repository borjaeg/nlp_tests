{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes\n",
    "\n",
    "Naïve Bayes classifiers are a family of classifiers that are based on the popular Bayes' probability theorem. They are known for creating simple yet well performing models, especially in the fields of document classification and disease prediction. This type of classifier ir linear and are know for being very efficient. The adjective **naive** come from the assumption that the features in the dataset are **mutually independent**. More exactly the sampres should be *i.i.d* (indepentend and identically distributed). One exaple of this behaviour would be coin tossing. In practice, the independende assumption is often violated byu the classifier still tends to perform correctly. Especially for **small datasets** naive Bayes classifiers can outperform the more powerful alternatives.\n",
    "\n",
    "Strong violations of the independence assumption and **non-linear classification problems** (instance based such as nearest neighbors would be better) can lead to very **poor performance**. In practice, it is always recommeded to compare different classification models on the particular dataset and consider the prediction performances as well as computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability model was formulated as follows\n",
    "\n",
    "$$\\text{posterior probability} = \\cfrac{\\text{Conditional Probability X Prior Probability}}{\\text{Evidence}}$$\n",
    "\n",
    "If the prior are following a **uniform distribution**, the posterior probabilities will be entirely determined by the class-conditional probabilities and the evidence term. And since the evidence term is a constant, the decision rule will wntirely depend on the class-conditional probabilities. Eventually the **a priori knowledge** can be obtained by consulting a domain expert or by estimation from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"http://scikit-learn.org/stable/modules/naive_bayes.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1040355d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://scikit-learn.org/stable/modules/naive_bayes.html\", width = 800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* **GaussianNB**: This classifier assumes the features to be normally distributed (Gaussian). This could be used to build a model that classifies people sex given their heights and weights. In text, using for example word counts, it probably doesn't work.\n",
    "\n",
    "* **MultinomialNB**: This classifier assumes the features to be occurrence counts. It also works well with TF-IDF vectors.\n",
    "\n",
    "* **BernouilliNB**: Similar to MultinomialNB, but more suited when using binary word occurrences.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Empirical comparisons provide evidence that the multinomial model tends to outperform the multi-variate Bernouilli model (binary data) if the vocabulary size is large enough. However, the performance of machine learning algorighms is highly dependent on the appropriate choice of features. In this case, performance can be attributed to the choices of stop word removal, stemming, and token-length.\n",
    "\n",
    "**In practice, it is recommended that the choice between a multi-variate Bernouilli or multinomial model for text classification should precede comparative studies including differents combinations of feature extraaction and selection step**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 150 points: 6. Total accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "print(\"Number of mislabeled points out of a total %d points: %d. Total accuracy: %.2f\" \\\n",
    "       % (iris.data.shape[0], (iris.target != y_pred).sum(), \\\n",
    "      (iris.target == y_pred).sum() / (iris.data.shape[0] * 1.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinombial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.randint(5, size=(6,100))\n",
    "y = np.array([1,2,3,4,5,6])\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.randint(5, size = (6,100))\n",
    "y = np.array([1,2,3,4,5,6])\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X[2:3] + np.random.randint(2, size=(1,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
