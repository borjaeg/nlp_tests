{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Every application is different**. We cannot offer a single evaluation metric that is right for any classification problem, or regression problem, or whatever problem you may encounter.\n",
    "\n",
    "It is useful to think of a **positive example** as one worth of atterntion or **alarm**, and a negative example as uninteresting or benign. \n",
    "\n",
    "### Plain Accuracy and its problems\n",
    "Classification accuracy is a popular metric because it's very easy to measure. Unfortunately, it is usually yoo simplistic for applications of data mining techniques to real business problems. To understand these problem we need a way to decompose and count different types of correct and incorrect decisions made by a classifier.\n",
    "\n",
    "### Confusion Matrix\n",
    "It is a kind of contingency problem. A confusion matrix separates the decision made by the classifier, making explicit how one class is being confused for another. In the confusion matrix, the main diagonal contains the counts of correct decisions.\n",
    "\n",
    "### Unbalanced classes\n",
    "Because the usunual or interesting class is rare among the general population, the class distribution is unbalanced or skewed. Unfortunately, as the class distribution becomes more skewed, evaluation based on accuracy breaks down. Even when the skew domains is not so great, in domains where one class is more prevalent than another accuracy can be greatly misleading.\n",
    "\n",
    "### Generalizing beyond classification\n",
    "Why is the mean-squared error on the predicted number of stars an appropriate metric for our recommendations problem? It it meaningful? is there a better metric? Hopefully, the analyst has thought this through carefully.\n",
    "\n",
    "While the probabilities can be estimated from data, the **costs** and **benefits** often cannot. They generally depend on external information provided by analysis of the consequences of decisions in the context of the specific **business problem**. Indeed, specifying the costs and benefits may take a great deal of time and though. In many cases, average estimated costs and benefits are used rather than individual-specific costs and benefits, for simplicity of problem formulation and calculation.\n",
    "\n",
    "Instead of computing accuracies for the competing models, we would compute expected values. Furthermore, using this alternative formulation, we can compare the two models even though one analyst tested using a representative distribution and the other tested using a class-balanced distribution.\n",
    "\n",
    "### Evaluation, Baseline Performance, and Implications for Investments in Data\n",
    "It is important to consider carefully what would be a reasonable baseline against which to compare the model performance. A data scientitest will often need to implement an alternative model, usually one that is simple but not simplistic, in order to justify continuing the data mining effort. \n",
    "\n",
    "Each model performs considerably better than random guessing, and both are so easy to compute that they make natura baselines of comparison. Any new,more complex model must beat these. \n",
    "\n",
    "What are some general guidelines for good baselines? For classification task, one good baseline is the **majority classifier**, a naive classifier that always chooses that majority class of the training dataset.\n",
    "\n",
    "Maximizing simple prediction accuracy is usually not an appropriate goal. If that's what our algorithm is doing, we're using the wrong algorithm. For regression problem, we have a directly analougous baseline: predict the average value over the population.\n",
    "\n",
    "Moving beyond these sample baseline models, a slightly more complex alternative that only considers a very small amount of feature information. One xample of mining such single-feature predictive models from data is to use tree induction to build a **decision stump** - a decision tree with only one internal node, the root node.  A decision stump often produce quite good baseline performance on many of the test datasets used in machine learning reaearch.\n",
    "\n",
    "Beyond comparing simple models (and reduced-data models), it is often useful to implement simple, inexpensive models based on domain knowledge or \"receive wisdom\" and evaluate their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
