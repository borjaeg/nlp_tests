{
 "metadata": {
  "name": "",
  "signature": "sha256:09d0eb4a9c8628eec29089e164fd53dbfafb055022ce4c4f9792128712298fe8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Sumarization\n",
      "\n",
      "Since summarization looks very complex, let's try a very intuitive approach. We will assume that summarization is nothing but ranking of the sentences based on their importance and significance to you. Moreover, typically, a sentence that has more entities and nouns has greater importance than other sentences. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "news_content = \\\n",
      "\"\"\" President Obama on Monday will ban the federal provision of some\n",
      "types of military-style equipment to local police departments and sharply\n",
      "restrict the availability of others, administration officials said.\n",
      "The ban is part of Mr. Obama's push to ease tensions between law\n",
      "enforcement and minority communities in reaction to the crises in\n",
      "Baltimore; Ferguson, Mo.; and other cities.\n",
      "-- -\n",
      "blic.\" It contains dozens of recommendations for agencies throughout the\n",
      "country.\"\"\"\n",
      "\n",
      "results = []\n",
      "for  sent_no, sentence in enumerate(nltk.sent_tokenize(news_content)):\n",
      "    no_of_tokens = len(nltk.word_tokenize(sentence))\n",
      "    # Let's do POS tagging\n",
      "    tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    # Count of the no of Nouns in the sentence\n",
      "    no_of_nouns = len([word for word, pos in tagged if pos in [\"NN\", \"NNP\"]])\n",
      "    # Use NER tag to named entities\n",
      "    ners = nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sentence)), binary = False)\n",
      "    no_of_ners = len([chunk for chunk in ners if hasattr(chunk, 'node')])\n",
      "    score = (no_of_ners + no_of_nouns)/ float(no_of_tokens)\n",
      "    results.append((sent_no, no_of_tokens, no_of_ners, no_of_nouns, score, sentence))    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in sorted(results, key=lambda x: x[4], reverse = True):\n",
      "    print sent[5]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The ban is part of Mr. Obama's push to ease tensions between law\n",
        "enforcement and minority communities in reaction to the crises in\n",
        "Baltimore; Ferguson, Mo.\n",
        " President Obama on Monday will ban the federal provision of some\n",
        "types of military-style equipment to local police departments and sharply\n",
        "restrict the availability of others, administration officials said.\n",
        "It contains dozens of recommendations for agencies throughout the\n",
        "country.\n",
        "; and other cities.\n",
        "-- -\n",
        "blic.\"\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = []\n",
      "\n",
      "news_content=\"\"\"Mr. Obama planned to promote the effort on Monday during\n",
      "a visit to Camden, N.J. The ban is part of Mr. Obama's push to ease\n",
      "tensions between law enforcement and minority communities in reaction to\n",
      "the crises in Baltimore; Ferguson, Mo. We are, without a doubt, sitting\n",
      "at a defining moment in American policing, Ronald L. Davis, the director\n",
      "of the Office of Community Oriented Policing Services at the Department\n",
      "of Justice, told reporters in a conference call organized by the White\n",
      "House\"\"\"\n",
      "\n",
      "sentences = nltk.sent_tokenize(news_content)\n",
      "vectorizer = TfidfVectorizer(norm='l2', min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True)\n",
      "sklearn_binary = vectorizer.fit_transform(sentences)\n",
      "print vectorizer.get_feature_names()\n",
      "print\n",
      "print sklearn_binary.toarray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'american', u'and', u'are', u'at', u'baltimore', u'ban', u'between', u'by', u'call', u'camden', u'communities', u'community', u'conference', u'crises', u'davis', u'defining', u'department', u'director', u'doubt', u'during', u'ease', u'effort', u'enforcement', u'ferguson', u'house', u'in', u'is', u'justice', u'law', u'minority', u'mo', u'moment', u'monday', u'mr', u'obama', u'of', u'office', u'on', u'organized', u'oriented', u'part', u'planned', u'policing', u'promote', u'push', u'reaction', u'reporters', u'ronald', u'services', u'sitting', u'tensions', u'the', u'to', u'told', u'visit', u'we', u'white', u'without']\n",
        "\n",
        "[[ 0.          0.          0.          0.          0.          0.          0.\n",
        "   0.          0.          0.30993994  0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.30993994\n",
        "   0.          0.30993994  0.          0.          0.          0.          0.\n",
        "   0.          0.          0.          0.          0.          0.30993994\n",
        "   0.20757039  0.20757039  0.          0.          0.30993994  0.          0.\n",
        "   0.          0.30993994  0.          0.30993994  0.          0.          0.\n",
        "   0.          0.          0.          0.          0.14768804  0.35144723\n",
        "   0.          0.30993994  0.          0.          0.        ]\n",
        " [ 0.          0.21532526  0.          0.          0.21532526  0.21532526\n",
        "   0.21532526  0.          0.          0.          0.21532526  0.          0.\n",
        "   0.21532526  0.          0.          0.          0.          0.          0.\n",
        "   0.21532526  0.          0.21532526  0.21532526  0.          0.24416171\n",
        "   0.21532526  0.          0.21532526  0.21532526  0.21532526  0.          0.\n",
        "   0.14420584  0.14420584  0.14420584  0.          0.          0.          0.\n",
        "   0.21532526  0.          0.          0.          0.21532526  0.21532526\n",
        "   0.          0.          0.          0.          0.21532526  0.17372306\n",
        "   0.24416171  0.          0.          0.          0.          0.        ]\n",
        " [ 0.16834073  0.          0.16834073  0.28502563  0.          0.          0.\n",
        "   0.16834073  0.16834073  0.          0.          0.16834073  0.16834073\n",
        "   0.          0.16834073  0.16834073  0.16834073  0.16834073  0.16834073\n",
        "   0.          0.          0.          0.          0.          0.16834073\n",
        "   0.19088498  0.          0.16834073  0.          0.          0.\n",
        "   0.16834073  0.          0.          0.          0.23659702  0.16834073\n",
        "   0.          0.16834073  0.16834073  0.          0.          0.28502563\n",
        "   0.          0.          0.          0.16834073  0.16834073  0.16834073\n",
        "   0.16834073  0.          0.19141722  0.          0.16834073  0.\n",
        "   0.16834073  0.16834073  0.16834073]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in sklearn_binary.toarray():\n",
      "    results.append(i.sum()/float(len(i.nonzero()[0])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}