{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the age of modern technology, there is one resource in aboundance: a large amount of structured and unstructured data. Machine leanring is a subfield of **artificial intelligence** that involved the development of self-learning algorithms to gain knowledge from the data to make predictions. Instead of requiring humans to manually derive rules and build models, machine learning offers a more efficient alternative for capturing the knowledge in data to gradually improve the performance of predictive models. Some examples are spam filters, voice recognition, search engines, and maybe soon, efficient self-driving cars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "The main goal is to learn from **labeled training data** that allows us to make prediction about unseen or future data. For example an **spam filtering** could be trained with labeled e-mails. There are two types of supervised learning:\n",
    "* Classification\n",
    "* Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "It is a subcategory of supervised learning where the goal is to predict the categorical class of the new instances based on past observations. Those class labels are discrete that can be understood as the group memberships of the instances. Spam classificaiton is an example of **binary classification** task, where the machine learning algorithm learns a set of rules in order to distinguish between two possible classes. However, there are also **multi-class** classification tasks such as handwritten character recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reinforcement Learning\n",
    "\n",
    "The goal is to develop a system that improves its perfomance based on interaction with the environment. Since the information about the current state of the environment typically also includes a so-called **reward** signal, we can think of reinforcement learning as a field related to **supervised learning**. However, in reinforcement learing this feedback is not the correct truth label or value, but a measure of how well the action was measured by a reaward function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a predictive model\n",
    "\n",
    "Each classification algorithm hast its inherit biases, and no single classificaiton model enjoys superiority if we don't make any assumptions about the task. In practice, it is therefore essential to comparesome different algorithms and select the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No free Lunch\n",
    "\n",
    "No single classifier works best across all possible scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"http://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1027219d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://ti.arc.nasa.gov/m/profile/dhw/papers/78.pdf\", width = 800, height = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "1. Selecting the features\n",
    "2. Choosing a performance metric\n",
    "3. Choosing a classifier and optimization algorithm\n",
    "4. Evaluating the performance of the model\n",
    "5. Tuning the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Eager and Lazy Learning Algorithms\n",
    "\n",
    "Being an **eager learner** (decision trees, naive Bayes, ANN, SVM, ...) are known to be relatively fast in classifying new instances. Eager learners learn a model from a training dataset, once the model is learned, the training data does not have tobe re-evaluated in order to make a new prediction. In case of eager learners, the computationally most expensive step is the model building step whereas the classification is relatively faster. **Lazy learners**, as k-nearest neighbors, memorize and re-evaluate the training dataset for predicting the class label of new instances. The advantage is that the model building (or training) phase is relatively fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
